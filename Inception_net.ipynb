{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Inception Architecture"]},{"cell_type":"markdown","metadata":{},"source":["### About GoogLeNet\n","- One particular incarnation based on the Inception Architecture\n","- The original paper **Going Deeper with Convolutions** can be found at <https://arxiv.org/abs/1409.4842>\n","- GoogLeNet, from Google Inc., is a 22 layers deep network that set the new SOTA results for classification / detection in ILSVRC 2014 (main competitor for VGGNet)"]},{"cell_type":"markdown","metadata":{},"source":["### The Inception Module\n","- Motivated by this meme \n","![](https://miro.medium.com/v2/resize:fit:1100/format:webp/1*hp93DT_YP2RfPs7eBDtPfw.jpeg \"Inception Movie meme\")\n","\n","- Two versions of the Inception Module were proposed: \n","![](https://media.geeksforgeeks.org/wp-content/uploads/20200429201304/Incepption-module.PNG \"Inception Modules\")\n","\n","- One major drawback of the na√Øve version - \"even a modest number of 5x5 convolutions can be prohibitively expensive on top of a convolutional layer with a large number of filters\" (i.e. problem related to the growth of the depth dimension of the output volume)\n","- This problem is exacerbated by the presence of pooling layers, which only lead to an inevitable increase in the number of channels in the output volume\n","- This problem is overcome by the clever introduction of 1x1 convolutions (these maintain the spatial resolution while reducing the depth dimension of the output volume) before the expensive 3x3 and 5x5 convolutions and after the pooling layers in the inception module\n"]},{"cell_type":"markdown","metadata":{},"source":["### Architecture of GoogLeNet\n","\n","![](https://media.geeksforgeeks.org/wp-content/uploads/20200429201421/Inception-layer-by-layer.PNG \"GoogLeNet Architecture\")"]},{"cell_type":"markdown","metadata":{},"source":["### Importing the necessary libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":6386,"status":"ok","timestamp":1638145650921,"user":{"displayName":"Gokulakrishnan CANDASSAMY","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNGyK-9yVRKWLm8l4bheSAj4FeQac-OwG0zRDd=s64","userId":"09874617787511296953"},"user_tz":480},"id":"BnUqPBt0zATL"},"outputs":[],"source":["import torch\n","import torch.nn as nn"]},{"cell_type":"markdown","metadata":{},"source":["### Implementing the GoogLeNet Architecture\n","1. First, we implement the conv_block class which implements a Convolution layer found in the Inception module\n","- Note that the usage of **kwargs in the constructor helps us construct conv layers with different parameters\n","2. Then, we implement the Inception_block class which invokes conv_block class multiple times as needed\n","- Note that there are 4 parallel branches in the Inception module with reductions, all of which can be computed in parallel\n","- The outputs from these branches are then concatenated along the depth dimension\n","3. Finally, we implement the GoogLeNet class which builds the entire architecture making use of Inception blocks "]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":161,"status":"ok","timestamp":1638153494079,"user":{"displayName":"Gokulakrishnan CANDASSAMY","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNGyK-9yVRKWLm8l4bheSAj4FeQac-OwG0zRDd=s64","userId":"09874617787511296953"},"user_tz":480},"id":"biZ4blBrFodI"},"outputs":[],"source":["class conv_block(nn.Module):\n","  def __init__(self, in_channels, out_channels, **kwargs):\n","    super(conv_block, self).__init__()\n","\n","    self.relu = nn.ReLU()\n","    self.conv = nn.Conv2d(in_channels, out_channels, **kwargs) #for ex. kernel_size = (1,1) or (3,3) or (5,5), we dont know in advance...\n","    self.batchnorm = nn.BatchNorm2d(out_channels)\n","\n","  def forward(self, x):\n","    return self.relu(self.batchnorm(self.conv(x)))"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["class Inception_block(nn.Module):\n","  def __init__(self, in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_1x1pool): #Refer to the inception block / all these params are # of filters.\n","    '''\n","    Args:\n","    in_channels : no of input channels\n","    out_1x1 : output from the first (leftmost) branch\n","    red_3x3 : depth reduction before 3x3 convolutions\n","    out_3x3 : output from the second branch\n","    red_5x5 : depth reduction before 5x5 convolutions\n","    out_5x5 : output from the third branch\n","    out_1x1pool: depth reduction after the pooling layer\n","    '''\n","    super(Inception_block, self).__init__()\n","\n","    self.branch1 = conv_block(in_channels, out_1x1, kernel_size=1)\n","    self.branch2 = nn.Sequential(\n","        conv_block(in_channels, red_3x3, kernel_size=1),\n","        conv_block(red_3x3, out_3x3, kernel_size=3, stride=1, padding=1) #by default stride=1 and padding=0\n","    )\n","    self.branch3 = nn.Sequential(\n","        conv_block(in_channels, red_5x5, kernel_size=1),\n","        conv_block(red_5x5, out_5x5, kernel_size=5, stride=1, padding=2)\n","    )\n","    self.branch4 = nn.Sequential(\n","        nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n","        conv_block(in_channels, out_1x1pool, kernel_size=1)\n","    )\n","  \n","  def forward(self,x):\n","    return torch.cat([self.branch1(x), self.branch2(x), self.branch3(x), self.branch4(x)], dim=1) #concatenate along C in N x C x H x W...\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["class GoogLeNet(nn.Module):\n","  def __init__(self, in_channels=3, num_classes=1000): #refer to the paper for the complete architecture to make sense...\n","    super(GoogLeNet, self).__init__()\n","\n","    self.conv1 = conv_block(in_channels=in_channels, out_channels=64, kernel_size=(7,7), stride=(2,2), padding=(3,3))\n","    self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) #can be reused wherever needed...\n","    self.conv2 = conv_block(64, 192, kernel_size=3, stride=1, padding=1)\n","\n","    #Now start the inception blocks...\n","    #Order of params for inception block: (in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_1x1pool)\n","    self.inception3a = Inception_block(192, 64, 96, 128, 16, 32, 32)\n","    self.inception3b = Inception_block(256, 128, 128, 192, 32, 96, 64)\n","\n","    self.inception4a = Inception_block(480, 192, 96, 208, 16, 48, 64)\n","    self.inception4b = Inception_block(512, 160, 112, 224, 24, 64, 64)\n","    self.inception4c = Inception_block(512, 128, 128, 256, 24, 64, 64)\n","    self.inception4d = Inception_block(512, 112, 144, 288, 32, 64, 64)\n","    self.inception4e = Inception_block(528, 256, 160, 320, 32, 128, 128)\n","\n","    self.inception5a = Inception_block(832, 256, 160, 320, 32, 128, 128)\n","    self.inception5b = Inception_block(832, 384, 192, 384, 48, 128, 128)\n","    self.avgpool = nn.AvgPool2d(kernel_size=7, stride=1)\n","    self.dropout = nn.Dropout(p=0.4)\n","    self.fc1 = nn.Linear(1024, 1000)\n","\n","  def forward(self, x):\n","    x = self.conv1(x)\n","    x = self.maxpool(x)\n","    x = self.conv2(x)\n","    x = self.maxpool(x)\n","\n","    x = self.inception3a(x)\n","    x = self.inception3b(x)\n","    x = self.maxpool(x)\n","\n","    x = self.inception4a(x)\n","    x = self.inception4b(x)\n","    x = self.inception4c(x)\n","    x = self.inception4d(x)\n","    x = self.inception4e(x)\n","    x = self.maxpool(x)\n","\n","    x = self.inception5a(x)\n","    x = self.inception5b(x)\n","    x = self.avgpool(x)\n","    x = x.reshape(x.shape[0], -1)\n","    x = self.dropout(x)\n","    x = self.fc1(x)\n","\n","    return x\n","     "]},{"cell_type":"markdown","metadata":{},"source":["### Sanity check..."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":681,"status":"ok","timestamp":1638153504106,"user":{"displayName":"Gokulakrishnan CANDASSAMY","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNGyK-9yVRKWLm8l4bheSAj4FeQac-OwG0zRDd=s64","userId":"09874617787511296953"},"user_tz":480},"id":"cNNC5MUHiamR","outputId":"dd870ffb-7bcc-46c3-a7f3-0d5c3cb18a17"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([3, 1000])\n"]}],"source":["x = torch.randn(3, 3, 224, 224)\n","model = GoogLeNet()\n","print(model(x).shape)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMo/YXqWHa1ccalFGqX/XeD","collapsed_sections":[],"name":"GoogLe_Net.ipynb","provenance":[]},"kernelspec":{"display_name":"dl_env","language":"python","name":"dl_env"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
